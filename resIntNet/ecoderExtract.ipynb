{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Pre-trained ProteinMPNN Model\n",
    "\n",
    "First, load the pre-trained ProteinMPNN model, ensuring you have the correct model architecture and class definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from protein_mpnn_utils import ProteinMPNN\n",
    "\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "#v_48_010=version with 48 edges 0.10A noise\n",
    "model_name = \"v_48_030\" #@param [\"v_48_002\", \"v_48_010\", \"v_48_020\", \"v_48_030\"]\n",
    "\n",
    "\n",
    "backbone_noise=0.00               # Standard deviation of Gaussian noise to add to backbone atoms\n",
    "\n",
    "path_to_model_weights='ProteinMPNN/vanilla_model_weights'\n",
    "hidden_dim = 128\n",
    "num_layers = 3\n",
    "model_folder_path = path_to_model_weights\n",
    "if model_folder_path[-1] != '/':\n",
    "    model_folder_path = model_folder_path + '/'\n",
    "checkpoint_path = model_folder_path + f'{model_name}.pt'\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "# Initialize the model\n",
    "proteinmpnn_model = ProteinMPNN(num_letters=21, node_features=hidden_dim, edge_features=hidden_dim, hidden_dim=hidden_dim, num_encoder_layers=num_layers, num_decoder_layers=num_layers, augment_eps=backbone_noise, k_neighbors=checkpoint['num_edges'])\n",
    "proteinmpnn_model.to(device)\n",
    "proteinmpnn_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "proteinmpnn_model.eval()\n",
    "print(\"Model loaded\")\n",
    "# Load the pre-trained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Encoder Weights\n",
    "Since the encoder is composed of multiple EncLayer instances within a ModuleList, you can directly access this list and its constituent layers. Each layer in the list is an instance of EncLayer, and you can work with them individually or as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the ModuleList of encoder layers\n",
    "encoder_layers = proteinmpnn_model.encoder_layers\n",
    "\n",
    "# You can iterate over each layer if needed\n",
    "for idx, enc_layer in enumerate(encoder_layers):\n",
    "    # Extract the state_dict of each encoder layer if needed\n",
    "    enc_layer_weights = enc_layer.state_dict()\n",
    "    # You can save or directly use these weights as per your requirement\n",
    "    # For example, saving weights with a layer-specific filename\n",
    "    torch.save(enc_layer_weights, f\"EncoderWeights/encoder_layer_{idx}_weights.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Encoder Weights in Your New Model\n",
    "When initializing the encoder layers in your new model, you can load these extracted weights into each corresponding layer. Ensure that the architecture of the encoder layers in your new model matches the architecture of the layers from which you extracted the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0-2): 3 x EncLayer(\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    (dropout3): Dropout(p=0.1, inplace=False)\n",
      "    (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (W1): Linear(in_features=384, out_features=128, bias=True)\n",
      "    (W2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (W3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (W11): Linear(in_features=384, out_features=128, bias=True)\n",
      "    (W12): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (W13): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense): PositionWiseFeedForward(\n",
      "      (W_in): Linear(in_features=128, out_features=512, bias=True)\n",
      "      (W_out): Linear(in_features=512, out_features=128, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from protein_mpnn_utils import EncLayer  # Ensure this is the same EncLayer used in ProteinMPNN\n",
    "\n",
    "# Initialize your new encoder layers (make sure it matches the original architecture)\n",
    "num_encoder_layers = num_layers\n",
    "new_encoder_layers = torch.nn.ModuleList([\n",
    "    EncLayer(hidden_dim, hidden_dim*2)\n",
    "    for _ in range(num_encoder_layers)\n",
    "])\n",
    "\n",
    "# Load weights into your new encoder layers\n",
    "for idx, enc_layer in enumerate(new_encoder_layers):\n",
    "    # Load the previously saved weights for each layer\n",
    "    enc_layer_weights = torch.load(f\"EncoderWeights/encoder_layer_{idx}_weights.pt\")\n",
    "    enc_layer.load_state_dict(enc_layer_weights)\n",
    "\n",
    "print(new_encoder_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considerations\n",
    "Ensure the new encoder layers have the same configuration (hidden_dim, dropout, etc.) as the original layers to guarantee compatibility.\n",
    "When extracting and using weights like this, be mindful of any preprocessing or postprocessing steps that might be required for the inputs or outputs of these layers, as such steps might be integral to how the encoder layers function within the context of the full ProteinMPNN model.\n",
    "If your use case involves modifying the encoder architecture or integrating it into a significantly different model, careful adjustments might be needed to ensure that the extracted weights remain effective in the new context.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
